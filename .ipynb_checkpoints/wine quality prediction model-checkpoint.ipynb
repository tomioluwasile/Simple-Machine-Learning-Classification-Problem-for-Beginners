{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are majorly using the scikit learn library, which comes with lots of pre-built functions and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required modules\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "%precision 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from the directory where your dataset is saved.\n",
    "data = pd.read_csv('winequality-red.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset head to have a feel of the type of data you're working with.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm non-null values\n",
    "# null values affect the accuracy of your model. If found, either avoid using such features or use the optional...\n",
    "# ...method of averages.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simply state our good and bad quality wine rules, transform the data as needed and assign x and y features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "# starting from good and bad wine quality rules\n",
    "bins = (2, 6.5, 8)\n",
    "group_names = ['bad', 'good']\n",
    "data['quality'] = pd.cut(data['quality'], bins = bins, labels = group_names)\n",
    "data['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the labelencoder\n",
    "data['quality'] = LabelEncoder().fit_transform(data['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset head again to confirm quality transformation\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y features\n",
    "X = data.drop('quality', axis = 1)\n",
    "y = data['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the number of good vs bad wine plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid bias, we use the StandardScaler from sklearn to ensure that all features are treated equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standard scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Applying Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn library also comes with several algorithms that can be applied easily and quickly. Since this is a classification problem, where output can only be good (1) or bad (0), let's try to use these three well known algorithms. You may include decision trees in your version of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rfc = RandomForestClassifier(n_estimators = 200)\n",
    "# fit in the data\n",
    "rfc.fit(X_train, y_train)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "pred_rfc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use the confusion_matrix and classification_report to measure model accuracy\n",
    "print(classification_report(y_test, pred_rfc))\n",
    "print(confusion_matrix(y_test, pred_rfc))\n",
    "rfc_accuracy = accuracy_score(y_test, pred_rfc)\n",
    "print('Model Accuracy:', str(rfc_accuracy * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest algoritm is 90% accurate. This is pretty good, can it be better? Let's try three more algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "lr = LogisticRegression(random_state=10, solver='liblinear')\n",
    "# fit in the data\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_lr[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_lr))\n",
    "print(confusion_matrix(y_test, pred_lr))\n",
    "lr_accuracy = accuracy_score(y_test, pred_lr)\n",
    "print('Model Accuracy:', str(lr_accuracy * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ran much faster than RFC, while maintaining a descent accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf = svm.SVC()\n",
    "# fit in the training data\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "pred_clf[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_clf))\n",
    "print(confusion_matrix(y_test, pred_clf))\n",
    "clf_accuracy = accuracy_score(y_test, pred_clf)\n",
    "print('Model Accuracy:', str(clf_accuracy * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM classifier also did a good job. Albeit, with an accuracy of 90%, it is safe to say the Random Forest Classifier is still our go-to algorithm. What about neural networks? Let's see how that will perform on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mlpc = MLPClassifier(hidden_layer_sizes = (11, 11, 11), max_iter = 2000)\n",
    "# fit in the training set\n",
    "mlpc.fit(X_train, y_train)\n",
    "pred_mlpc = mlpc.predict(X_test)\n",
    "pred_mlpc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_mlpc))\n",
    "print(confusion_matrix(y_test, pred_mlpc))\n",
    "mlpc_accuracy = accuracy_score(y_test, pred_mlpc)\n",
    "print('Model Accuracy:', str(mlpc_accuracy * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really good as well. It goes to show that you may select either Random Forest Classifier, Logistic Regression or Neural Networks for this problem. However, when results are too close in this kind of case, you may choose to select an algorithm based on the time it takes it to run. \n",
    "\n",
    "In this case, the fastest algorithm that still holds a descent accuracy score is Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test new data\n",
    "Xnew = [[7.5, 0.60, 0.06, 1.5, 0.055, 13.0, 30.0, 0.9950, 3.33, 0.56, 9.8]]\n",
    "Xnew = sc.transform(Xnew)\n",
    "ynew_rfc = rfc.predict(Xnew)\n",
    "ynew_lr = lr.predict(Xnew)\n",
    "ynew_clf = clf.predict(Xnew)\n",
    "ynew_mlpc = mlpc.predict(Xnew)\n",
    "print('Wine quality (RFC):', ynew_rfc)\n",
    "print('Wine quality (LR):', ynew_lr)\n",
    "print('Wine quality (SVM):', ynew_clf)\n",
    "print('Wine quality (Neural Networks):', ynew_mlpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test existing good wine\n",
    "wine = [[7.8, 0.58, 0.02, 2.0, 0.073, 9.0, 18.0, 0.9968, 3.36, 0.57, 9.5]]\n",
    "wine = sc.transform(wine)\n",
    "ynew_rfc = rfc.predict(wine)\n",
    "ynew_lr = lr.predict(wine)\n",
    "ynew_clf = clf.predict(wine)\n",
    "ynew_mlpc = mlpc.predict(wine)\n",
    "print('Wine quality (RFC):', ynew_rfc)\n",
    "print('Wine quality (LR):', ynew_lr)\n",
    "print('Wine quality (SVM):', ynew_clf)\n",
    "print('Wine quality (Neural Networks):', ynew_mlpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What esle? A good next step would be to try out more algoritms like decision trees or k-nearest neighbors. Then you can add the \"%%timeit\" function to check runtime of each algorithm and choose the optimal algorithm you wish."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
